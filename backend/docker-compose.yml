version: '3.8'
services:
  nginx:
    image: nginx:alpine
    container_name: landingpage-nginx
    ports:
      - "8080:80"  # Public port for landing page
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ..:/usr/share/nginx/html:ro  # Mount entire parent directory to nginx root
    depends_on:
      - n8n
    restart: unless-stopped
    networks:
      - demo

  n8n:
    image: n8nio/n8n:latest
    container_name: landingpage-n8n-ai
    ports:
      - "5680:5678"  # Map internal n8n port 5678 to host port 5680
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678  # Internal n8n port
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:8080/n8n/
      - N8N_PATH=/n8n/
      - N8N_EDITOR_BASE_URL=http://localhost:8080/n8n/
      - N8N_METRICS=true
      - GENERIC_TIMEZONE=Europe/Berlin
      - OLLAMA_HOST=ollama:11434
    volumes:
      - n8n_storage:/home/node/.n8n
    restart: unless-stopped
    networks:
      - demo

  # Postgres for n8n AI starter kit (optional but recommended)
  postgres:
    image: postgres:15-alpine
    container_name: landingpage-postgres
    environment:
      - POSTGRES_DB=n8n
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=n8n_password_change_me
    volumes:
      - postgres_storage:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - demo

  # Qdrant vector database for AI features
  qdrant:
    image: qdrant/qdrant:latest
    container_name: landingpage-qdrant
    ports:
      - "6333:6333"  # Qdrant API
    volumes:
      - qdrant_storage:/qdrant/storage
    restart: unless-stopped
    networks:
      - demo

  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    container_name: landingpage-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama
    restart: unless-stopped
    networks:
      - demo

volumes:
  n8n_storage:
  postgres_storage:
  qdrant_storage:
  ollama_storage:

networks:
  demo:
    driver: bridge
